# global_market_news_app.pyï¼ˆåŠ ä¸Šæ—¥æœŸé¡¯ç¤º + åŠ å…¥ Yahoo Financeï¼‰
import streamlit as st
import requests
from bs4 import BeautifulSoup
from datetime import datetime

st.set_page_config(page_title="å…¨çƒè²¡ç¶“é ­æ¢èˆ‡å¸‚å ´å½±éŸ¿å¿«å ±", layout="wide")
st.title("ğŸŒ å…¨çƒè²¡ç¶“é ­æ¢ + ç¾è‚¡èˆ‡é»ƒé‡‘å¸‚å ´å½±éŸ¿åˆ†æ")
st.markdown(f"ğŸ—“ï¸ ä»Šæ—¥æ—¥æœŸï¼š{datetime.today().strftime('%Y-%m-%d')}")

# Reuters æ–°èæ“·å–
@st.cache_data
def get_reuters_headlines():
    try:
        url = "https://www.reuters.com/world/"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.select("article.story-card")
        headlines = []
        for article in articles[:5]:
            h = article.find(['h3', 'h2'])
            if h and h.text.strip():
                headlines.append(h.text.strip())
        return headlines
    except:
        return ["âš ï¸ ç„¡æ³•æ“·å– Reuters ä¸–ç•Œæ–°è"]

# Bloomberg æ–°èæ“·å–
@st.cache_data
def get_bloomberg_headlines():
    try:
        url = "https://www.bloomberg.com"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.find_all('a', href=True)
        titles = []
        for a in articles:
            title = a.get_text().strip()
            href = a['href']
            if len(title) > 25 and "/news" in href and title not in titles:
                titles.append(title)
        return titles[:5]
    except:
        return ["âš ï¸ ç„¡æ³•æ“·å– Bloomberg æ–°è"]

# Yahoo Finance æ–°èæ“·å–
@st.cache_data
def get_yahoo_headlines():
    try:
        url = "https://finance.yahoo.com"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        items = soup.find_all('h3')
        headlines = [i.get_text().strip() for i in items if len(i.get_text().strip()) > 20]
        return headlines[:5]
    except:
        return ["âš ï¸ ç„¡æ³•æ“·å– Yahoo Finance æ–°è"]

# ç°¡æ˜“æ¨™ç±¤ + AI é¢¨æ ¼æ‘˜è¦

def analyze_headline(headline):
    headline_lower = headline.lower()
    stock_keywords = ["fed", "interest rate", "inflation", "nasdaq", "apple", "jobs", "tech", "treasury"]
    gold_keywords = ["gold", "precious", "usd", "dollar", "geopolitical", "china", "safe haven", "central bank"]

    related_to_stock = any(keyword in headline_lower for keyword in stock_keywords)
    related_to_gold = any(keyword in headline_lower for keyword in gold_keywords)

    if related_to_stock and related_to_gold:
        tag = "ğŸ“ˆ ç¾è‚¡ & ğŸª™ é»ƒé‡‘"
        summary = "é€™å‰‡æ–°èåŒæ™‚é—œè¯åˆ©ç‡èˆ‡é¿éšªä¸»é¡Œï¼Œå¯èƒ½å½±éŸ¿é»ƒé‡‘èˆ‡è‚¡å¸‚èµ°å‹¢ã€‚"
    elif related_to_stock:
        tag = "ğŸ“ˆ ç¾è‚¡"
        summary = "é€™å‰‡æ–°èèˆ‡ç¾è‚¡å¸‚å ´ç›¸é—œï¼Œå¯èƒ½å½±éŸ¿æŠ•è³‡äººå°æ”¿ç­–æˆ–ä¼æ¥­çš„é æœŸã€‚"
    elif related_to_gold:
        tag = "ğŸª™ é»ƒé‡‘"
        summary = "é€™å‰‡æ–°èèˆ‡é»ƒé‡‘åƒ¹æ ¼ç›¸é—œï¼Œå¯èƒ½å› å¸‚å ´é¿éšªéœ€æ±‚å‡æº«æˆ–ç¾å…ƒè®Šå‹•æ‰€è‡´ã€‚"
    else:
        tag = ""
        summary = "ä¸€èˆ¬æ€§åœ‹éš›æ–°èï¼Œç›®å‰å°šç„¡æ˜ç¢ºé‡‘èå¸‚å ´é€£çµã€‚"
    return
