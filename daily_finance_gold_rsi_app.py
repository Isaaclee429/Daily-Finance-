# global_market_news_app.pyï¼ˆInvesting æ”¹ç‚º RSS + é¡¯ç¤ºé€£çµï¼‰
import streamlit as st
import requests
from bs4 import BeautifulSoup
import feedparser
from datetime import datetime

st.set_page_config(page_title="å…¨çƒè²¡ç¶“é ­æ¢èˆ‡å¸‚å ´å½±éŸ¿å¿«å ±", layout="wide")
st.title("ğŸŒ å…¨çƒè²¡ç¶“é ­æ¢ + ç¾è‚¡èˆ‡é»ƒé‡‘å¸‚å ´å½±éŸ¿åˆ†æ")
st.markdown(f"ğŸ—“ï¸ ä»Šæ—¥æ—¥æœŸï¼š{datetime.today().strftime('%Y-%m-%d')}")

# Reuters æ–°èæ“·å–
@st.cache_data
def get_reuters_headlines():
    try:
        url = "https://www.reuters.com/world/"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.select("article.story-card")
        headlines = []
        for article in articles[:5]:
            h = article.find(['h3', 'h2'])
            if h and h.text.strip():
                headlines.append({"title": h.text.strip(), "link": url})
        return headlines
    except:
        return [{"title": "âš ï¸ ç„¡æ³•æ“·å– Reuters ä¸–ç•Œæ–°è", "link": ""}]

# Bloomberg æ–°èæ“·å–
@st.cache_data
def get_bloomberg_headlines():
    try:
        url = "https://www.bloomberg.com"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.find_all('a', href=True)
        titles = []
        for a in articles:
            title = a.get_text().strip()
            href = a['href']
            if (
                "/news" in href and
                20 < len(title) < 150 and
                not any(x in title.lower() for x in ["photo", "bloomberg", "getty", "video", "/live/"])
            ):
                full_url = href if href.startswith("http") else f"https://www.bloomberg.com{href}"
                titles.append({"title": title, "link": full_url})
        return titles[:5] if titles else [{"title": "âš ï¸ Bloomberg ç„¡æ¨™é¡Œ", "link": ""}]
    except:
        return [{"title": "âš ï¸ ç„¡æ³•æ“·å– Bloomberg æ–°è", "link": ""}]

# Investing RSS æ“·å–
@st.cache_data
def get_investing_rss():
    try:
        feed = feedparser.parse("https://www.investing.com/rss/news_25.rss")
        entries = feed.entries[:5]
        return [{"title": e.title, "link": e.link} for e in entries]
    except:
        return [{"title": "âš ï¸ ç„¡æ³•æ“·å– Investing.com RSS", "link": ""}]

# åˆ†ææ¨™ç±¤èˆ‡æ‘˜è¦

def analyze_headline(headline):
    headline_lower = headline.lower()
    stock_keywords = ["fed", "interest rate", "inflation", "nasdaq", "apple", "jobs", "tech", "treasury"]
    gold_keywords = ["gold", "precious", "usd", "dollar", "geopolitical", "china", "safe haven", "central bank"]

    related_to_stock = any(keyword in headline_lower for keyword in stock_keywords)
    related_to_gold = any(keyword in headline_lower for keyword in gold_keywords)

    if related_to_stock and related_to_gold:
        tag = "ğŸ“ˆ ç¾è‚¡ & ğŸª™ é»ƒé‡‘"
        summary = "åŒæ™‚æ¶‰åŠè‚¡å¸‚èˆ‡é»ƒé‡‘ç›¸é—œè­°é¡Œï¼Œå¯èƒ½å°å…©è€…çš†é€ æˆå½±éŸ¿ã€‚"
    elif related_to_stock:
        tag = "ğŸ“ˆ ç¾è‚¡"
        summary = "èˆ‡è‚¡å¸‚ã€åˆ©ç‡ã€å°±æ¥­æˆ–ä¼æ¥­è²¡å ±ç­‰è­°é¡Œç›¸é—œã€‚"
    elif related_to_gold:
        tag = "ğŸª™ é»ƒé‡‘"
        summary = "èˆ‡é¿éšªæƒ…ç·’ã€ç¾å…ƒèµ°å‹¢æˆ–é»ƒé‡‘éœ€æ±‚ç›¸é—œã€‚"
    else:
        tag = ""
        summary = "æ–°èèˆ‡é‡‘èå¸‚å ´ç„¡ç›´æ¥é—œè¯ï¼Œä½†å¯è§€å¯ŸèƒŒæ™¯ç™¼å±•ã€‚"
    return tag, summary

# é¡¯ç¤ºå€å¡Š

def display_news(source_title, news_list):
    st.subheader(f"ğŸ“° {source_title}")
    for i, item in enumerate(news_list, 1):
        tag, summary = analyze_headline(item['title'])
        st.markdown(f"**{i}. [{item['title']}]({item['link']})**  {tag}")
        st.markdown(f"ğŸ“Œ {summary}")
        st.markdown("---")

# é¡¯ç¤ºå„ä¾†æºæ–°è
display_news("Reuters åœ‹éš›æ–°è", get_reuters_headlines())
display_news("Bloomberg ç„¦é»æ–°è", get_bloomberg_headlines())
display_news("Investing.com RSS æ–°è", get_investing_rss())
